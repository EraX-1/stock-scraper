# Stock Scraper Production Container
# Based on qast-scraper architecture for Azure Container Instances deployment

FROM node:20-bullseye

# Install dependencies for Playwright Chromium
RUN apt-get update && apt-get install -y \
    wget \
    ca-certificates \
    fonts-liberation \
    libappindicator3-1 \
    libasound2 \
    libatk-bridge2.0-0 \
    libatk1.0-0 \
    libcups2 \
    libdbus-1-3 \
    libdrm2 \
    libgtk-3-0 \
    libnspr4 \
    libnss3 \
    libx11-xcb1 \
    libxcomposite1 \
    libxdamage1 \
    libxrandr2 \
    xdg-utils \
    libxss1 \
    libasound2 \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy package files
COPY package*.json ./

# Install all dependencies (including dev for TypeScript compilation)
RUN npm ci

# Install Playwright with Chromium browser
RUN npx playwright install chromium
RUN npx playwright install-deps chromium

# Copy TypeScript configuration
COPY tsconfig.json ./

# Copy source code
COPY src/ src/

# Build the application
RUN npm run build

# Create directories for data storage
RUN mkdir -p stock-mhtml
RUN mkdir -p session

# Set environment variables for Stock Scraper
ENV NODE_ENV=production
ENV HEADLESS=true
ENV DEBUG=false

# Stock application specific
ENV STOCK_LOGIN_URL=https://www.stock-app.jp/teams/sign-in
ENV STOCK_URL=https://www.stock-app.jp/teams/c20282/dashboard

# Scraping configuration (stock-scraper specific)
ENV SCRAPE_CONCURRENCY=1
ENV SCRAPE_BATCH_SIZE=5
ENV SCRAPE_TIMEOUT_MS=120000
ENV PAGE_LOAD_DELAY=5000
ENV REQUEST_DELAY_MS=5000
ENV MAX_RETRY_ATTEMPTS=3

# Performance settings for container environment
ENV SCRAPE_DELAY_MS=5000
ENV BATCH_DELAY_MS=2000
ENV NETWORK_TIMEOUT=90000

# Default command runs the container main entry point with verbose logging
CMD ["sh", "-c", "echo 'ğŸš€ Starting Stock Scraper Container...' && npm start 2>&1 | tee /dev/stderr"]